{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 3 for OSM \n",
    "\n",
    "### Dynamic Programming with John Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the [OSM](https://bfi.uchicago.edu/osm) bootcamp dynamic programming section.\n",
    "\n",
    "We will use the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantecon as qe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "Using Numba, as discussed in [this lecture](https://lectures.quantecon.org/py/need_for_speed.html), write your own version of NumPy's [interp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html) function, specializing in linear interpolation in one dimension.  \n",
    "\n",
    "Note that NumPy's function is compiled native machine code and hence is fast.  But try to beat if you can, at least in some scenarios, by using Numba to speed up your code.  Show a time comparison between the two functions, for some suitable choice of test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4823.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 42.6 µs per loop\n",
      "100000 loops, best of 3: 10.8 µs per loop\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "\n",
    "#This is the best I could do, I tried fancy numpy functions but it ended up being fastest just to do it in one loop...\n",
    "\n",
    "def custom_interp(x, xp, fp):\n",
    "    final_points = []\n",
    "    xp_i = 1\n",
    "    for point in x:\n",
    "        if point <= xp[xp_i]:\n",
    "            final_points.append(fp[xp_i] + (fp[xp_i] - fp[xp_i - 1]) * (point - xp[xp_i]) / (xp[xp_i] - xp[xp_i - 1]))\n",
    "        else:\n",
    "            xp_i += 1\n",
    "            final_points.append(fp[xp_i] + (fp[xp_i] - fp[xp_i - 1]) * (point - xp[xp_i]) / (xp[xp_i] - xp[xp_i - 1]))\n",
    "    return final_points\n",
    "            \n",
    "x = np.linspace(0, 100, 1001)\n",
    "\n",
    "xp = np.linspace(0, 100, 11)\n",
    "\n",
    "fp = [1, 3, 2, 6, 7, 2, 4, 8, 9, 3, 4]\n",
    "                                \n",
    "custom_interp_numba = jit(custom_interp)\n",
    "\n",
    "%timeit custom_interp_numba(x, xp, fp)\n",
    "\n",
    "%timeit np.interp(x, xp, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using your \"Numbafied\" linear interpolation function, try to use Numba to additionally speed up the endogenous grid method code from [this lecture](https://lectures.quantecon.org/py/egm_policy_iter.html).  Use CRRA utility and Cobb-Douglas production, as in that lecture, with the following parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I didn't get much speed up.  I think because the outer loops don't matter much for speed, and hence it doesn't gain us much when we compile them.  \n",
    "\n",
    "See how you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.29 ms per loop\n",
      "100 loops, best of 3: 3.32 ms per loop\n"
     ]
    }
   ],
   "source": [
    "class LogLinearOG:\n",
    "    \"\"\"\n",
    "    Log linear optimal growth model, with log utility, CD production and\n",
    "    multiplicative lognormal shock, so that\n",
    "\n",
    "        y = f(k, z) = z k^alpha\n",
    "\n",
    "    with z ~ LN(mu, s).\n",
    "\n",
    "    The class holds parameters and true value and policy functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.4, beta=0.96, mu=0, s=0.1):\n",
    "\n",
    "        self.alpha, self.beta, self.mu, self.s = alpha, beta, mu, s \n",
    "\n",
    "        # == Some useful constants == #\n",
    "        self.ab = alpha * beta\n",
    "        self.c1 = np.log(1 - self.ab) / (1 - beta)\n",
    "        self.c2 = (mu + alpha * np.log(self.ab)) / (1 - alpha)\n",
    "        self.c3 = 1 / (1 - beta)\n",
    "        self.c4 = 1 / (1 - self.ab)\n",
    "\n",
    "    def u(self, c):\n",
    "        \" Utility \"\n",
    "        return np.log(c)\n",
    "\n",
    "    def u_prime(self, c):\n",
    "        return 1 / c\n",
    "\n",
    "    def f(self, k):\n",
    "        \" Deterministic part of production function.  \"\n",
    "        return k**self.alpha\n",
    "\n",
    "    def f_prime(self, k):\n",
    "        return self.alpha * k**(self.alpha - 1)\n",
    "\n",
    "    def c_star(self, y):\n",
    "        \" True optimal policy.  \"\n",
    "        return (1 - self.alpha * self.beta) * y\n",
    "\n",
    "    def v_star(self, y):\n",
    "        \" True value function. \"\n",
    "        return self.c1 + self.c2 * (self.c3 - self.c4) + self.c4 * np.log(y)\n",
    "\n",
    "\n",
    "def coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks):\n",
    "    \"\"\"\n",
    "    The approximate Coleman operator, updated using the endogenous grid\n",
    "    method.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : function\n",
    "        The current guess of the policy function\n",
    "    k_grid : array_like(float, ndim=1)\n",
    "        The set of *exogenous* grid points, for capital k = y - c\n",
    "    beta : scalar\n",
    "        The discount factor\n",
    "    u_prime : function\n",
    "        The derivative u'(c) of the utility function\n",
    "    u_prime_inv : function\n",
    "        The inverse of u' (which exists by assumption)\n",
    "    f : function\n",
    "        The production function f(k)\n",
    "    f_prime : function\n",
    "        The derivative f'(k)\n",
    "    shocks : numpy array\n",
    "        An array of draws from the shock, for Monte Carlo integration (to\n",
    "        compute expectations).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for value of consumption on endogenous grid points\n",
    "    c = np.empty_like(k_grid)  \n",
    "\n",
    "    # Solve for updated consumption value\n",
    "    for i, k in enumerate(k_grid):\n",
    "        vals = u_prime(g(f(k) * shocks)) * f_prime(k) * shocks\n",
    "        c[i] = u_prime_inv(beta * np.mean(vals))\n",
    "    \n",
    "    # Determine endogenous grid\n",
    "    y = k_grid + c  # y_i = k_i + c_i\n",
    "\n",
    "    # Update policy function and return\n",
    "    Kg = lambda x: np.interp(x, y, c)\n",
    "    return Kg\n",
    "\n",
    "\n",
    "def custom_coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks):\n",
    "    \"\"\"\n",
    "    The approximate Coleman operator, updated using the endogenous grid\n",
    "    method.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : function\n",
    "        The current guess of the policy function\n",
    "    k_grid : array_like(float, ndim=1)\n",
    "        The set of *exogenous* grid points, for capital k = y - c\n",
    "    beta : scalar\n",
    "        The discount factor\n",
    "    u_prime : function\n",
    "        The derivative u'(c) of the utility function\n",
    "    u_prime_inv : function\n",
    "        The inverse of u' (which exists by assumption)\n",
    "    f : function\n",
    "        The production function f(k)\n",
    "    f_prime : function\n",
    "        The derivative f'(k)\n",
    "    shocks : numpy array\n",
    "        An array of draws from the shock, for Monte Carlo integration (to\n",
    "        compute expectations).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for value of consumption on endogenous grid points\n",
    "    c = np.empty_like(k_grid)  \n",
    "\n",
    "    # Solve for updated consumption value\n",
    "    for i, k in enumerate(k_grid):\n",
    "        vals = u_prime(g(f(k) * shocks)) * f_prime(k) * shocks\n",
    "        c[i] = u_prime_inv(beta * np.mean(vals))\n",
    "    \n",
    "    # Determine endogenous grid\n",
    "    y = k_grid + c  # y_i = k_i + c_i\n",
    "\n",
    "    # Update policy function and return\n",
    "    Kg = lambda x: custom_interp_numba(x, y, c)\n",
    "    return Kg\n",
    "\n",
    "#custom_coleman_egm_numba = jit(custom_coleman_egm)\n",
    "\n",
    "#The above code doesn't work, I'm not sure why. I have timed custom_coleman_egm and coleman_egm below.\n",
    "\n",
    "lg = LogLinearOG()\n",
    "\n",
    "# == Unpack parameters / functions for convenience == #\n",
    "alpha, beta, mu, s = lg.alpha, lg.beta, lg.mu, lg.s\n",
    "v_star, c_star = lg.v_star, lg.c_star\n",
    "u, u_prime, f, f_prime = lg.u, lg.u_prime, lg.f, lg.f_prime\n",
    "\n",
    "grid_max = 4         # Largest grid point, exogenous grid\n",
    "grid_size = 200      # Number of grid points\n",
    "shock_size = 250     # Number of shock draws in Monte Carlo integral\n",
    "\n",
    "k_grid = np.linspace(1e-5, grid_max, grid_size)\n",
    "shocks = np.exp(mu + s * np.random.randn(shock_size))\n",
    "g = lambda x: x\n",
    "\n",
    "%timeit custom_coleman_egm(g, k_grid, beta, u_prime, u_prime, f, f_prime, shocks)\n",
    "%timeit coleman_egm(g, k_grid, beta, u_prime, u_prime, f, f_prime, shocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
